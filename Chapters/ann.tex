\begin{center}
    \begin{figure}[htp]
        \centering
        \begin{tikzpicture}[
        plain/.style={
          draw=none,
          fill=none,
          },
        dot/.style={draw,shape=circle,minimum size=3pt,inner sep=0,fill=black
          },
        net/.style={
          matrix of nodes,
          nodes={
            draw,
            circle,
            inner sep=8.5pt
            },
          nodes in empty cells,
          column sep=0.6cm,
          row sep=-11pt
          },
        >=latex
        ]
        \matrix[net] (mat)
        {
        |[plain]| \parbox{1cm}{\centering Input\\layer} 
                  & |[plain]| \parbox{1cm}{\centering Hidden\\layer} 
                               & |[plain]| \parbox{1cm}{\centering Output\\layer} \\
                  & |[plain]|                 \\
        |[plain]| &            & |[plain]|    \\
                  & |[plain]|  &              \\
        |[plain]| & |[dot]|                   \\
                  & |[plain]|  & |[dot]|      \\
        |[plain]| & |[dot]|    & |[plain]|    \\
        |[dot]|   & |[plain]|  & |[dot]|      \\
        |[dot]|   & |[dot]|    & |[plain]|    \\
        |[dot]|   & |[plain]|  &              \\
        |[plain]| &            & |[plain]|    \\
                  & |[plain]|                 \\
        };
        \foreach \ai/\mi in {2/I1,4/I2,6/I3,12/In}
          \draw[<-] (mat-\ai-1) -- node[above] {\mi} +(-1cm,0);
        \foreach \ai in {2,4,6,12}
        {\foreach \aii/\mii in {3/H1,11/Hn}
          \draw[->] (mat-\ai-1) -- (mat-\aii-2) node[yshift=0.6cm] {\mii};
        }
        \foreach \ai in {3,11}
        {  \draw[->] (mat-\ai-2) -- (mat-4-3);
          \draw[->] (mat-4-3) -- node[above] {O1} +(1cm,0);}
        \foreach \ai in {3,11}
        {  \draw[->] (mat-\ai-2) -- (mat-10-3);
          \draw[->] (mat-10-3) -- node[above] {On} +(1cm,0);}
        \end{tikzpicture}
        
        \caption{Multi Layered Neural Network diagram.}
        \label{fig_m_3}
        \end{figure}
\end{center}

The perceptron model acts as the base for all the functioning of modern multi-layered neural networks.
The output of the single neuron described in the above perceptron is taken as the input in the next layer of the network. The above figure(1.1) shows an example of multi-layered neural where the first layer is known 
as input layer and intermediate layers are called hidden layers and the last layer is known as the output layer.
The single neuron can perform limited computation but the computation power increases with inter-connected
neurons in the network \citep{AGATONOVICKUSTRIN2000717} where at each layer information is processed through the appropriate 
activation function. Artificial neural networks are designed to learn the patterns and relationships in the data and requires enough amount of data to train and predict accurate outputs \citep{AGATONOVICKUSTRIN2000717}.
The training data is passed to the neural network to recognise the patterns in data and each iteration or epoch 
the model prediction gets improved with the optimisation algorithm which propagates through the network to 
update the weights and bias to increase the accuracy \citep{AGATONOVICKUSTRIN2000717}. The accuracy of the neural networks are determined through various hyper-parameters such as learning rate, number of hidden layers in the model and 
number of epochs for which the model is trained. The fundamental rule for learning in artifical model 


